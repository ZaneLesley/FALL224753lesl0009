---
title: "Assignment 1"
author: "Zane Lesley"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
setwd("C:/Users/Zanel/OneDrive/Desktop/FALL 2024 STATS/FALL224753lesl0009/Lab/Lab1")
ddt=read.csv("DDT.csv")
head(ddt)
```
# Tasks

## Q1

In Class Quizzes - 10%
Labs = 10%
Chapter Quizzes - 5%
Project 1 - 3.33%
Project 2 - 6.67%
Exam 1 - 10%
Exam 2 - 10%
Assignments - 15%
Final Exam - 30%

Normal grading, but B is extended to 70%+ and C is 60%+.

## Q2

```{r}
m = with(ddt, as.numeric(factor(MILE)))
length(unique(m))

with(ddt, coplot(LENGTH~WEIGHT | RIVER*SPECIES, row=1, col=m))
```

### b)
The catfish were very similar within Length and weight, being found in different rivers as well at different miles.

### c)
factor() essentially converts the MILE into a list of values, which as.numeric then converts those unique values
into numeric values.

### d)
unique(m) makes each of those numeric values unique, consisting of only one of each type, which length gives how many of those values there
are.

### e)
No Large mouth bass or small buffalo fish exist in those rivers.

### f)
```{r}
mean(ddt[ddt$RIVER == "FCM" & ddt$SPECIES == "CCATFISH"]$DDT)
```

## Q3)
a. Quantitative 
b. Quantitative
c. Qualitative
d. Quantitative
e. Qualitative
f. Quantitative
g. Qualitative

## Q4)

simple random - select x amount of data points using a random number generator to assign them to the sample.

stratified random sampling - data points are chosen when you can categorical sort the data points into groups that are more 
similar within their strata vs across the sample's strata. We then get random samples from within those strata. 
(speed limit example 25mph, 40mph, or 55mph depending on max street speed limit)

cluster sampling - sample a certain amount from the whole population, so pick 10 of 150 programs, then examine each program for errors.

systematic sampling - select ever nth data point in the population.

## Q5)
```{r}
setwd("C:/Users/Zanel/OneDrive/Desktop/FALL 2024 STATS/FALL224753lesl0009/Assignment/ASS1")
mtbe = read.csv("MTBE.csv")
ind = sample(1:223, 5, replace=FALSE)
mtbe[ind,]
```

### a)
```{r}
mtbeo = na.omit(mtbe)
sd(mtbeo[mtbeo$Aquifier == "Bedrock",]$Depth)
```

## Q6)
```{r}
setwd("C:/Users/Zanel/OneDrive/Desktop/FALL 2024 STATS/FALL224753lesl0009/Assignment/ASS1")
eq = read.csv("EARTHQUAKE.csv")
rm(ind)
ind = sample(1:2929, 30, replace=FALSE)
eq[ind,]
```

### ai)
```{r}
plot(ts(eq$MAG))
```

### aii
```{r}
median(eq$MAGNITUDE)
```

## Q7)

Stratified Random Sampling 

The population is the fish in the rivers, the sample would be the fish they caught.

River, Species.

## Q8)
a. Bar 
b. Types of Robotic Limbs
c. Legs Only
d. 15,8,63,20
### e)
```{r}
freq = c(15, 8, 63, 20)
RL = c("None", "Both", "Legs","Wheels")
l = rep(RL, freq)
source("pareto.r")
pareto(l)
```

## Q9)
```{r}
freq = c(6, 8, 22, 3, 11)
RL = c("DDOS", "ID", "RCE","Spoofing", "PE")
l = rep(RL, freq)

pie(freq, labels=RL)
pareto(l)
```

## Q10)
```{r}
swd = read.csv("SWDEFECTS.csv", header=TRUE)
library(plotrix)
tab=table(swd$defect)
rtab=tab/sum(tab)
round(rtab, 2)
pie3D(rtab, labels=list("OK", "Defective"), main="pie plot of SWD")
```

The piechart shows that most of the software is good and not defective, while a small portion of it is still defective.

## Q11)
```{r}
volt = read.csv("VOLTAGE.csv")
subvolt <- subset(volt, subset=LOCATION=="OLD")
oldvolt = subvolt$VOLTAGE
freq = round(((max(oldvolt) - min(oldvolt)) / 9), 4)
lept = 8.0
rept = 10.6
cl = seq(lept, rept, by=freq)
cutvolt <- cut(oldvolt, breaks=cl)
new.tab=table(cutvolt)
barplot(new.tab, space=0, main="Old Volt Frequency Histogram", las=2, col=rainbow(2))
stem(oldvolt, scale=2)
```

### b)
Essentially, they both show the same thing, the difference being in the stem-and-leaf plot we are not having any intervals and instead
are sorting by the exact values, whereas in the barplot we are showing more so a summary of frequencies. I would say the barplot is more of a quick overview, whereas the stem-and-leaf is much more precise and has more inherit information.

###c)
```{r}
volt = read.csv("VOLTAGE.csv")
subvolt <- subset(volt, subset=LOCATION=="NEW")
newvolt = subvolt$VOLTAGE
freq = round(((max(newvolt) - min(oldvolt)) / 9), 4)
lept = 8.0
rept = 10.6
cl = seq(lept, rept, by=freq)
cutvolt <- cut(newvolt, breaks=cl)
new.tab=table(cutvolt)
barplot(new.tab, space=0, main="New Volt Frequency Histogram", las=2, col=rainbow(2))
stem(newvolt, scale=2)
```

### d)

At the old location we only have 4 readings under 9.2 which would be considered bad, whereas at the new location we have 9 readings under 9.2. So the old location is still better has we have less readings under 9.2.

### e) mean, median, mode (in order)
```{r}
cat("old locations:\n")
mean(oldvolt)
median(oldvolt)
sorted = sort(table(oldvolt), decreasing = TRUE)
names(sorted)[1]
cat("new locations:\n")
mean(newvolt)
median(newvolt)
sorted = sort(table(newvolt), decreasing = TRUE)
names(sorted)[1]
```

### f-h)
```{r}
old_z = (10.50 - mean(oldvolt)) / sd(oldvolt) 
old_z
new_z = (10.50 - mean(newvolt)) / sd(newvolt) 
new_z
```
It is more likely to occur at the old location as the z-score is closer to 0.

### i-j)
```{r}
boxplot(oldvolt, ylab="Voltage")
z = (oldvolt - mean(oldvolt)) / sd(oldvolt)
oldvolt[abs(z) > 2]
```
Yes, each dot outside of the whiskers is an outlier. 

### k-l)
```{r}
boxplot(newvolt, ylab="Voltage")
rm(z)
z = (newvolt - mean(newvolt)) / sd(newvolt)
newvolt[abs(z) > 2]
```
No points are abs(z) > 2 of the standard deviation for the new voltage values.

### m)

Most of the data for the old voltage is much more centralized with less variance around the SD, so the values that are equal as extreme in the new voltage show up as outliers in the old voltage location.

## Q12)
```{r}
pipe = read.csv("ROUGHPIPE.csv")
pipero = pipe$ROUGH

c(mean(pipero) - 2 * sd(pipero), mean(pipero) + 2 * sd(pipero))
```

## Q13)
```{r}
ants = read.csv("GOBIANTS.csv")

mean(ants$AntSpecies)
median(ants$AntSpecies)
sorted = sort(table(ants$AntSpecies), decreasing = TRUE)
names(sorted)[1]
```
Because of the outliers in 52 and 49, i think the mean is swayed too far up, so in this case I would use the median for the central tendency. In general with this small of a sample, I wouldn't recommend using the mode.

### c)
```{r}
dry_ants = ants[ants$AntSpecies & ants$Region=="Dry Steppe",] 
mean(dry_ants$AntSpecies)
median(dry_ants$AntSpecies)
sorted = sort(table(dry_ants$AntSpecies), decreasing = TRUE)
names(sorted)[1]
```
### d)
```{r}
gobi_ants = ants[ants$AntSpecies & ants$Region=="Gobi Desert",] 
mean(gobi_ants$AntSpecies)
median(gobi_ants$AntSpecies)
sorted = sort(table(gobi_ants$AntSpecies), decreasing = TRUE)
names(sorted)[1]
```
### e)

The values aren't too far away from each other, but they aren't too different from each other


## Q14)
```{r}
galaxy = read.csv("GALAXY2.csv")

hist(galaxy$VELOCITY, col=rainbow(2), xlab="Velocity (km/s)", main="Histogram of Galaxies' Velocity")
```
Yes, we see two bell curvish shapes, indicating that there could be 2 galaxies, one where the central tendency between 19000-20000, and one around 22000-23000.





















